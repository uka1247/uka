
import streamlit as st
import openai
import re
import random
import csv
import os
from datetime import datetime
import streamlit.components.v1 as components

# ğŸ”‘ OpenAI APIã‚­ãƒ¼ã‚’è¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰ï¼‰
api_key = os.getenv("OPENAI_API_KEY")
client = openai.OpenAI(api_key=api_key)

# ğŸŒ ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="PolyView AI", layout="centered")

# ğŸ’… ã‚«ã‚¹ã‚¿ãƒ CSSã§ãŠã—ã‚ƒã‚Œã«
st.markdown("""
    <style>
        body {
            background-color: #f9f9f9;
            font-family: 'Helvetica Neue', sans-serif;
        }
        .main-title {
            font-size: 2.5em;
            font-weight: bold;
            color: #2C3E50;
            margin-bottom: 0.2em;
        }
        .subtext {
            font-size: 1.1em;
            color: #7F8C8D;
            margin-bottom: 2em;
        }
        .box {
            background-color: #ffffff;
            border-radius: 16px;
            padding: 20px;
            box-shadow: 0px 4px 12px rgba(0,0,0,0.06);
            margin-top: 20px;
        }
        .agree {
            border-left: 6px solid #51A3FF;
        }
        .disagree {
            border-left: 6px solid #FF6B6B;
        }
        .extra {
            border-left: 6px solid #BDC3C7;
            font-style: normal;
            color: #4a4a4a;
        }
        .stTextArea textarea {
            background-color: #ffffff !important;
            border-radius: 8px !important;
        }
    </style>
""", unsafe_allow_html=True)


# =========================
# ãƒ˜ãƒƒãƒ€ãƒ¼
# =========================
st.markdown('<div class="main-title">ğŸ§  PolyView AI</div>', unsafe_allow_html=True)
st.markdown('<div class="subtext">è³›å¦ã‚’æç¤ºã—ã€è£œè¶³ã¯ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ï¼ˆå‚è€ƒæƒ…å ±æºï¼‰ã‚’æ˜ç¤ºã—ã¾ã™</div>', unsafe_allow_html=True)

# =========================
# ãƒˆãƒ”ãƒƒã‚¯ä¾‹ï¼ˆã‚¯ãƒªãƒƒã‚¯ã§ã‚³ãƒ”ãƒ¼ï¼‰
# =========================
st.markdown("<div style='color:#7f8c8d; font-size:0.95em; margin-bottom:0.5em;'>ğŸ” æœ€è¿‘ã®æ°—ã«ãªã‚‹ãƒ¯ãƒ¼ãƒ‰</div>", unsafe_allow_html=True)

topics = [
    "ãƒ™ãƒ¼ã‚·ãƒƒã‚¯ã‚¤ãƒ³ã‚«ãƒ ã¯å°å…¥ã™ã¹ãã ã¨æ€ã†ï¼Ÿ",
    "æ­»åˆ‘åˆ¶åº¦ã¯å€«ç†ã«åã—ã¦ã‚‹ï¼Ÿ",
    "å¤§å­¦ã®ç„¡å„ŸåŒ–ã«ã¯è³›æˆï¼Ÿåå¯¾ï¼Ÿ",
    "åŸç™ºã¯å¿…è¦ã ã¨æ€ã†ï¼Ÿ",
    "åŒæ€§å©šã¯ã‚ã‚Šï¼Ÿ",
    "AIã«è¦åˆ¶ã¯å¿…è¦ï¼Ÿ",
    "é¸æŒ™æ¨©å¹´é½¢ã¯18æ­³ã®ã¾ã¾ã§ã„ã„ï¼Ÿ",
    "å…¬å…±äº¤é€šã¯ç„¡æ–™ã«ã™ã¹ãï¼Ÿ",
    "ç§»æ°‘ã®å—ã‘å…¥ã‚Œ",
    "SNSã§ã®ç™ºè¨€ã«åŒ¿åæ€§ã¯å¿…è¦ã‹ï¼Ÿ",
    "ãƒã‚¤ãƒŠãƒ³ãƒãƒ¼ã‚«ãƒ¼ãƒ‰ã®ç¾©å‹™åŒ–ã«è³›æˆï¼Ÿ",
    "æ—¥æœ¬ã¯é˜²è¡›åŠ›ã‚’å¼·åŒ–ã™ã¹ãã‹ï¼Ÿ",
    "ã‚³ãƒ³ãƒ“ãƒ‹ã®24æ™‚é–“å–¶æ¥­ã¯å¿…è¦ï¼Ÿ",
    "çµ¦é£Ÿã®ç„¡å„ŸåŒ–ã¯å…¨å›½ã§å®Ÿæ–½ã—ãŸæ–¹ãŒã„ã„ï¼Ÿ",
    "é€±ä¼‘3æ—¥åˆ¶ã¯å°å…¥ã™ã¹ãï¼Ÿ",
    "é¸æŒ™ã¯ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æŠ•ç¥¨ã‚’å°å…¥ã™ã¹ãï¼Ÿ",
    "ã‚¸ã‚§ãƒ³ãƒ€ãƒ¼æ•™è‚²ã¯ç¾©å‹™æ•™è‚²ã«å«ã‚ãŸæ–¹ãŒã„ã„ã®ã‹",
    "ã‚«ã‚¸ãƒã¯åˆæ³•åŒ–ã§OKï¼Ÿ",
    "å‹•ç‰©å®Ÿé¨“ã¯å€«ç†çš„ã«è¨±ã•ã‚Œã‚‹ï¼Ÿ",
    "æœ€è¿‘ã®ãƒˆãƒ©ãƒ³ãƒ—æ”¿æ¨©ã«ã¤ã„ã¦",
    "æ¶ˆè²»ç¨æ’¤å»ƒ",
    "æ”¿æ²»å®¶ã®è£é‡‘å•é¡Œ",
    "ãƒã‚¹ã‚³ãƒŸã«ã‚ˆã‚‹æƒ…å ±çµ±åˆ¶ã¯æ’¤å»ƒã™ã¹ãï¼Ÿ",
]
random_topics = random.sample(topics, 4)

cards_html = "<div style='display:flex; justify-content:center; gap:20px; flex-wrap:nowrap;'>"
for t in random_topics:
    safe_t = t.replace("'", "\\'")
    cards_html += f"""
    <div onclick="navigator.clipboard.writeText('{safe_t}')" style='
        width: 200px; min-height: 100px; padding: 16px;
        background-color: white; border-radius: 16px;
        box-shadow: 0 2px 6px rgba(0,0,0,0.1);
        font-size: 1em; text-align: center;
        display: flex; align-items: center; justify-content: center;
        line-height: 1.4em; cursor: pointer; transition: 0.2s;
    ' onmouseover="this.style.backgroundColor='#f4f4f4'" onmouseout="this.style.backgroundColor='white'">
        {t}
    </div>
    """
cards_html += "</div>"
components.html(cards_html, height=180)

# =========================
# Utility
# =========================
def _get(obj, key, default=None):
    if obj is None:
        return default
    if isinstance(obj, dict):
        return obj.get(key, default)
    return getattr(obj, key, default)

def parse_agree_disagree(text: str):
    agree_match = re.search(r"ğŸ”µ\s*è³›æˆã®ç«‹å ´ï¼š\s*(.*?)(?=ğŸ”´|$)", text, re.DOTALL)
    disagree_match = re.search(r"ğŸ”´\s*è¦–ç‚¹ã‚’ãšã‚‰ã—ãŸç«‹å ´ï¼š\s*(.*?)(?=$)", text, re.DOTALL)
    agree = agree_match.group(1).strip() if agree_match else ""
    disagree = disagree_match.group(1).strip() if disagree_match else ""
    return agree, disagree

def extract_url_citations(resp):
    """
    Responses APIã®æˆ»ã‚Šã‹ã‚‰ url_citationï¼ˆtitle/urlï¼‰ã‚’æŠ½å‡º
    """
    cits = []
    output = _get(resp, "output", []) or []
    for item in output:
        if _get(item, "type") != "message":
            continue
        contents = _get(item, "content", []) or []
        for part in contents:
            if _get(part, "type") != "output_text":
                continue
            annotations = _get(part, "annotations", []) or []
            for ann in annotations:
                if _get(ann, "type") == "url_citation":
                    url = _get(ann, "url", "") or ""
                    title = _get(ann, "title", "") or "(no title)"
                    if url:
                        cits.append({"title": title, "url": url})

    # URLã§é‡è¤‡æ’é™¤
    seen = set()
    uniq = []
    for c in cits:
        if c["url"] not in seen:
            uniq.append(c)
            seen.add(c["url"])
    return uniq

def clean_extra_text(text: str) -> str:
    """
    è£œè¶³æ å†…ã‹ã‚‰ãƒªãƒ³ã‚¯ã‚’æ¶ˆã™ï¼†ã€Œå‚è€ƒæƒ…å ±æºã€ãªã©ã®ä½™è¨ˆãªéƒ¨åˆ†ã‚’ã‚«ãƒƒãƒˆ
    - Markdownãƒªãƒ³ã‚¯ [text](url) -> text
    - ç”ŸURL https://... ã‚’é™¤å»
    - ã€Œå‚è€ƒæƒ…å ±æº/References/Sourcesã€è¦‹å‡ºã—ä»¥é™ã‚’ã‚«ãƒƒãƒˆ
    """
    if not text:
        return ""

    # è¦‹å‡ºã—ã£ã½ã„èªãŒå‡ºãŸã‚‰ä»¥é™ã‚’ã‚«ãƒƒãƒˆ
    text = re.sub(r"\n\s*(å‚è€ƒæƒ…å ±æº|References|Sources).*", "", text, flags=re.IGNORECASE | re.DOTALL)

    # Markdownãƒªãƒ³ã‚¯ã‚’æ–‡å­—ã ã‘ã«
    text = re.sub(r"\[([^\]]+)\]\((https?://[^\)]+)\)", r"\1", text)

    # ç”ŸURLã‚’é™¤å»
    text = re.sub(r"https?://\S+", "", text)

    # ä½™ç™½æ•´å½¢
    text = re.sub(r"[ \t]+", " ", text)
    text = re.sub(r"\n{3,}", "\n\n", text).strip()

    return text

def to_safe_html(text: str) -> str:
    """
    HTMLè¡¨ç¤ºç”¨ï¼šã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ï¼‹æ”¹è¡Œã‚’<br>ã«å¤‰æ›ï¼ˆãƒªãƒ³ã‚¯åŒ–ã•ã›ãªã„ï¼‰
    """
    safe = html_lib.escape(text or "")
    return safe.replace("\n", "<br>")

# =========================
# å…¥åŠ›æ¬„
# =========================
user_input = st.text_area("ğŸ’¬ ã‚ãªãŸã®æ„è¦‹ã‚’ã”è‡ªç”±ã«å…¥åŠ›ã—ã¦ãã ã•ã„", height=150)

# =========================
# å®Ÿè¡Œ
# =========================
if st.button("âœ¨ åˆ†æã™ã‚‹") and user_input.strip():
    with st.spinner("AIãŒåˆ†æä¸­ã§ã™..."):

        # ã“ã“ã§ã‚‚æ¯å›åˆæœŸåŒ–ï¼ˆã•ã‚‰ã«å®‰å…¨ï¼‰
        citations = []
        extra_text_display = ""

        # -------------------------
        # 1) ğŸ”µğŸ”´ï¼ˆé€šå¸¸ç”Ÿæˆï¼šWebæ¤œç´¢ãªã—ï¼‰
        # -------------------------
        system_main = (
            "ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„è¦‹ã«å¯¾ã—ã¦ã€è³›æˆã¨åå¯¾ï¼ˆè¦–ç‚¹ãšã‚‰ã—ï¼‰ã®ä¸¡æ–¹ã®è¦–ç‚¹ã‚’æç¤ºã™ã‚‹AIã§ã™ã€‚"
            "åå¯¾æ„è¦‹ã¯å¤šæ§˜ãªç«‹å ´ã®ä¸€ä¾‹ã‚’ç¤ºã™ã“ã¨ã€‚æ¥µç«¯ãªå¦å®šã‚„æ‰‡æƒ…çš„ãªè¡¨ç¾ã¯é¿ã‘ã€è«–ç†çš„ã§å»ºè¨­çš„ã«ã€‚"
            "ã“ã“ã§ã¯è£œè¶³ã¯æ›¸ã‹ãªã„ã§ãã ã•ã„ã€‚"
        )

        user_main = f"""
ä»¥ä¸‹ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„è¦‹ã§ã™ï¼š
ã€Œ{user_input}ã€

ã“ã®æ„è¦‹ã«å¯¾ã—ã¦ã€ä»¥ä¸‹ã®å½¢å¼ã§â€œå¿…ãšâ€å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆè£œè¶³ã¯å‡ºåŠ›ã—ãªã„ï¼‰ï¼š

ğŸ”µ è³›æˆã®ç«‹å ´ï¼š
ç°¡æ½”ã«è³›æˆæ„è¦‹ã‚’2ã€œ7æ–‡ã§è¿°ã¹ã¦ãã ã•ã„ã€‚

ğŸ”´ è¦–ç‚¹ã‚’ãšã‚‰ã—ãŸç«‹å ´ï¼š
ç°¡æ½”ã«åå¯¾æ„è¦‹ã‚’2ã€œ7æ–‡ã§è¿°ã¹ã¦ãã ã•ã„ã€‚åå¯¾æ„è¦‹ã¯å¤šæ§˜ãªç«‹å ´ã®ä¸€ä¾‹ã‚’ç¤ºã™ã“ã¨ã€‚æ¥µç«¯ãªå¦å®šã‚„æ‰‡æƒ…çš„ãªè¡¨ç¾ã¯é¿ã‘ã€è«–ç†çš„ã§å»ºè¨­çš„ã«æç¤ºã—ã¦ãã ã•ã„ã€‚
"""

        try:
            main_resp = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_main},
                    {"role": "user", "content": user_main},
                ],
            )
            main_text = main_resp.choices[0].message.content or ""
        except Exception:
            main_text = ""

        agree_text, disagree_text = parse_agree_disagree(main_text)

        # -------------------------
        # 2) è£œè¶³ï¼ˆWebæ¤œç´¢ã‚ã‚Šï¼‰
        # -------------------------
        prefixes = [
            "è£œè¶³ã«ãªã‚Šã¾ã™ãŒã€",
            "ã¡ãªã¿ã«ã€",
            "å¿µã®ãŸã‚ä»˜ã‘åŠ ãˆã‚‹ã¨ã€",
            "ã“ã“ã§ä¸€ã¤ã ã‘è£œè¶³ã™ã‚‹ã¨ã€",
            "è©±é¡Œã‚’åºƒã’ã‚‹æ„å‘³ã§è£œè¶³ã™ã‚‹ã¨ã€",
        ]
        chosen_prefix = random.choice(prefixes)

        extra_prompt = f"""
ä»¥ä¸‹ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„è¦‹ã§ã™ï¼š
ã€Œ{user_input}ã€

ã“ã®æ„è¦‹ã«é–¢é€£ã™ã‚‹æœ€è¿‘ã®ç¤¾ä¼šçš„æ–‡è„ˆãƒ»å ±é“ãƒ»çµ±è¨ˆãƒ»æ”¿ç­–ãªã©ã®æƒ…å ±ã‚’è¸ã¾ãˆã¤ã¤ã€
ä¸­ç«‹çš„ãªã€Œè£œè¶³ã€ã‚’2ã€œ5æ–‡ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚

åˆ¶ç´„ï¼š
- å†’é ­ã¯å¿…ãšã€Œ{chosen_prefix}ã€ã§å§‹ã‚ã‚‹
- èªã‚Šå£ã¯ç©ã‚„ã‹ã§ã€èª­è€…ã«è€ƒãˆã‚‹ä½™åœ°ã‚’æ®‹ã™
- æ–­å®šã—ã™ããšã€å¿…è¦ã«å¿œã˜ã¦ã€Œã€œã¨ã•ã‚Œã‚‹ã€ã€Œã€œã¨ã®æŒ‡æ‘˜ãŒã‚ã‚‹ã€ãªã©ã§èª¿æ•´ã™ã‚‹
- æ¥µç«¯ã«æ‰‡æƒ…çš„ãªè¨€ã„å›ã—ã¯é¿ã‘ã‚‹
- â€œè£œè¶³æ–‡ã®ã¿â€ã‚’å‡ºåŠ›ï¼ˆå‚è€ƒæƒ…å ±æºãƒ»URLãƒ»ç®‡æ¡æ›¸ããƒ»è¦‹å‡ºã—ã¯å‡ºåŠ›ã—ãªã„ï¼‰
"""

        extra_text_raw = ""
        try:
            extra_resp = client.responses.create(
                model="gpt-4o",
                input=extra_prompt,
                tools=[{"type": "web_search"}],
                include=["web_search_call.action.sources"],
            )
            extra_text_raw = (getattr(extra_resp, "output_text", "") or "").strip()
            citations = extract_url_citations(extra_resp) or []
        except Exception:
            extra_text_raw = "è£œè¶³ã®ç”Ÿæˆæ™‚ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚æ™‚é–“ã‚’ãŠã„ã¦å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
            citations = []

        # âœ… è£œè¶³æ å†…ãƒªãƒ³ã‚¯é™¤å»ï¼ˆè¡¨ç¤ºç”¨ï¼‰
        extra_text_display = clean_extra_text(extra_text_raw)

        # =========================
        # è¡¨ç¤ºï¼ˆHTMLã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã§ãƒªãƒ³ã‚¯åŒ–ã‚‚å°ã˜ã‚‹ï¼‰
        # =========================
        st.markdown("### ğŸ” AIã«ã‚ˆã‚‹2ã¤ã®è¦–ç‚¹ã¨è£œè¶³")

        if agree_text:
            st.markdown(
                f'<div class="box agree"><strong>ğŸ”µ è³›æˆã®ç«‹å ´ï¼š</strong><br>{to_safe_html(agree_text)}</div>',
                unsafe_allow_html=True
            )
        else:
            st.warning("âš ï¸ è³›æˆã®ç«‹å ´ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

        if disagree_text:
            st.markdown(
                f'<div class="box disagree"><strong>ğŸ”´ è¦–ç‚¹ã‚’ãšã‚‰ã—ãŸç«‹å ´ï¼š</strong><br>{to_safe_html(disagree_text)}</div>',
                unsafe_allow_html=True
            )
        else:
            st.warning("âš ï¸ è¦–ç‚¹ã‚’ãšã‚‰ã—ãŸç«‹å ´ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

        if extra_text_display:
            # âœ… è£œè¶³æ ã¯ãƒªãƒ³ã‚¯ç„¡ã—ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã®ã¿ï¼‰
            st.markdown(
                f'<div class="box extra">{to_safe_html(extra_text_display)}</div>',
                unsafe_allow_html=True
            )
        else:
            st.warning("âš ï¸ è£œè¶³ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

        # âœ… å‚è€ƒæƒ…å ±æºï¼ˆã“ã“ã ã‘ã§è¡¨ç¤ºï¼‰
        if citations:
            st.markdown("#### å‚è€ƒæƒ…å ±æºï¼ˆè£œè¶³ã§å‚ç…§ï¼‰")
            for i, c in enumerate(citations, 1):
                title = (c.get("title") or "(no title)").strip()
                url = (c.get("url") or "").strip()
                if url:
                    st.markdown(f"{i}. [{title}]({url})")
        else:
            st.caption("ï¼ˆä»Šå›ã®è£œè¶³ã§ã¯ã€å‚ç…§URLãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰")

        # =========================
        # âœ… CSVãƒ­ã‚°ä¿å­˜ï¼ˆãƒœã‚¿ãƒ³å†…ã ã‘ã§å®Ÿè¡Œï¼‰
        # =========================
        log_path = "liberal_ai_log.csv"
        now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        file_exists = os.path.isfile(log_path)

        # json.dumpsã®å®‰å…¨åŒ–ï¼šå¿…ãšãƒªã‚¹ãƒˆã«ã™ã‚‹ï¼ˆNameError/å‹å´©ã‚Œå¯¾ç­–ï¼‰
        sources_json = json.dumps(citations if isinstance(citations, list) else [], ensure_ascii=False)

        with open(log_path, mode="a", newline="", encoding="utf-8") as file:
            writer = csv.writer(file)
            if not file_exists:
                writer.writerow(["timestamp", "user_input", "agree", "disagree", "extra", "sources_json"])
            writer.writerow([
                now,
                user_input.strip(),
                agree_text,
                disagree_text,
                extra_text_display,
                sources_json,
            ])

            
